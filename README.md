<div align="center">
    <h1>WikiAnc</h1>
    <p>
    A program for generating the WikiAnc dataset.
    </p>
</div>
<p align="center">
    <img alt="License" src="https://img.shields.io/github/license/cyanic-selkie/wikianc?label=license">
</p>

## Usage

You can find the pregenerated dataset on Huggingface (March 1, 2023):
* [English](https://huggingface.co/datasets/cyanic-selkie/wikianc-en)
* [Croatian](https://huggingface.co/datasets/cyanic-selkie/wikianc-hr)

If you want to regenerate the dataset with fresh Wikipedia/Wikidata dumps, you can build `wikianc` from source by running the following command:

```bash
cargo build --release
```

**NOTE:** The program uses language specific filtering (i.e., the word "file") which only supports Croatian and English out of the box. Replace the relevant part in the `parse_links` function to properly support your language.

`wikianc` uses the mappings between Wikipedia titles and Wikidata QIDs generated by [wiki2qid](https://github.com/cyanic-selkie/wiki2qid). Follow the instructions to generate the [Apache Avro](https://avro.apache.org/) file containing the mappings first.

It also uses a Wikipedia dump in an `ndjson` format which can be generated by following the instructions [here](https://github.com/cyanic-selkie/wiki2ndjson).

Once you have the necessary data, you can generate the dataset with the following command:
```bash
cargo run --release -- \
        --input-wiki "${WIKIPEDIA_NDJSON_FILE}" \
        --input-wiki2qid "${MAPPINGS_FILE}" \
        --output-dir "${OUTPUT_DIR}"
```

This will create 3 files named `train.parquet`, `validation.parquet`, and `test.parquet` in the directory specified by `${OUTPUT_DIR}`.

The outputs are written into [zstd](https://github.com/facebook/zstd) compressed [Apache Parquet](https://parquet.apache.org/) files. You can see the details of the schema on [Huggingface](https://huggingface.co/datasets/cyanic-selkie/wikianc-en).

## Performance

`WikiAnc` uses as many threads as there are logical CPU cores. On the English dump from March 2023, containing ~6,600,000 articles, it takes \~11 minutes to complete with peak memory usage of ~52GB on an AMD Ryzen Threadripper 3970X CPU and an SSD.
